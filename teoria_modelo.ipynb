{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séries Temporais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhendo o Melhor Método\n",
    "\n",
    "\n",
    "Padrões Lineares Simples: ARIMA ou Exponential Smoothing.\n",
    "\n",
    "\n",
    "Padrões Lineares com Sazonalidade: SARIMA ou ETS.\n",
    "\n",
    "\n",
    "Padrões Não Lineares: Modelos de árvore de decisão como Random Forest ou XGBoost.\n",
    "\n",
    "\n",
    "Dependências de Longo Prazo: LSTMs ou Transformers.\n",
    "\n",
    "\n",
    "Fatores Exógenos Complexos: XGBoost, LightGBM ou Redes Neurais.\n",
    "\n",
    "\n",
    "Recomendado testar diferentes modelos, usar validação cruzada e métricas como MAE (Mean Absolute Error) ou RMSE (Root Mean Squared Error) para avaliar o desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modelos Estatísticos Clássicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA (AutoRegressive Integrated Moving Average)\n",
    "Quando usar: Se os dados têm uma tendência linear ou sazonalidade. ARIMA é útil para séries temporais estacionárias (dados flutuam em torno de uma mesma média e variância). *Se não for estacionário, usar o parâmetro *d* para aplicar diferenciação. \n",
    "\n",
    "**Vantagens:** Simplicidade e boa performance em dados lineares. \n",
    "\n",
    "**Desvantagens:** Não lida bem com padrões não lineares ou com muitos fatores exógenos. \n",
    "\n",
    "**Como usar:** O modelo pode ser ajustado para capturar dependências temporais, sazonalidade e tendências. \n",
    "\n",
    "**Importante:** Parâmetros **p**,**d** e **q**, usar o auto.arima() para achar os com as menores métricas AIC,AICc e BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(df['coluna'], order=(p,d,q))\n",
    "model_fit = model.fit()\n",
    "pred = model_fit.forecast(steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA (Seasonal ARIMA)\n",
    "**Quando usar:** Se os dados apresentam sazonalidade, além de tendências e padrões autorregressivos.\n",
    "\n",
    "\n",
    "**Vantagens:** Estende o ARIMA para capturar padrões sazonais.\n",
    "\n",
    "\n",
    "**Desvantagens:** Pode ser difícil de ajustar os parâmetros sazonais.\n",
    "\n",
    "\n",
    "**Como usar:** Adicione parâmetros sazonais ao modelo ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing (ETS)\n",
    "**Quando usar:** Para séries temporais com tendência ou sazonalidade que precisam de suavização.\n",
    "\n",
    "\n",
    "**Vantagens:** Bom para capturar tendências e sazonalidade com uma abordagem simples.\n",
    "\n",
    "\n",
    "**Desvantagens:** Não captura bem padrões complexos.\n",
    "\n",
    "\n",
    "**Como usar:** Implementado através do método Holt-Winters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "model = ExponentialSmoothing(df['coluna'], seasonal='add', seasonal_periods=12)\n",
    "model_fit = model.fit()\n",
    "pred = model_fit.forecast(steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelos de Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "**Quando usar:** Se houver fatores exógenos e a série temporal não for linear.\n",
    "\n",
    "\n",
    "**Vantagens:** Capta interações não lineares entre as variáveis.\n",
    "\n",
    "\n",
    "**Desvantagens:** Pode não capturar bem a dependência temporal a longo prazo.\n",
    "\n",
    "\n",
    "**Como usar:** Construa um modelo com as variáveis temporais e outras variáveis explicativas (como lag features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost/LightGBM\n",
    "**Quando usar:** Para séries temporais com dependências não lineares e várias variáveis explicativas.\n",
    "\n",
    "\n",
    "**Vantagens:** Alto desempenho, especialmente em problemas com alta dimensionalidade e interações complexas.\n",
    "\n",
    "\n",
    "**Desvantagens:** Requer otimização dos hiperparâmetros para bons resultados.\n",
    "\n",
    "\n",
    "**Como usar:** Semelhante ao Random Forest, você pode treinar o modelo com features temporais (lags, médias móveis, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelos Baseados em Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory)\n",
    "\n",
    "**Quando usar:** Para séries temporais com longas dependências temporais, como fluxos de caixa complexos, onde padrões sazonais ou de tendência são menos lineares.\n",
    "\n",
    "\n",
    "**Vantagens:** Captura bem padrões a longo prazo e dinâmicas temporais complexas.\n",
    "\n",
    "\n",
    "**Desvantagens:** Requer mais dados e recursos computacionais. Pode ser mais difícil de treinar e ajustar.\n",
    "\n",
    "\n",
    "**Como usar:** Redes LSTM funcionam bem quando as dependências entre os dados em diferentes intervalos de tempo são complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(timesteps, features)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Models\n",
    "**Quando usar:** Para séries temporais com dados complexos, muitos fatores exógenos ou interdependências entre variáveis.\n",
    "\n",
    "\n",
    "**Vantagens:** Desempenho de ponta em tarefas sequenciais e temporais. Captura relações a longo prazo sem necessidade de manter sequências explícitas, como nas LSTMs.\n",
    "\n",
    "\n",
    "**Desvantagens:** Alta complexidade e demanda computacional.\n",
    "\n",
    "\n",
    "**Como usar:** Modelos transformers podem ser treinados com grandes datasets e são adequados para dados complexos e multivariados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelos Híbridos\n",
    "\n",
    "**Quando usar:** Quando os dados apresentam padrões complexos que não são completamente capturados por um único tipo de modelo.\n",
    "\n",
    "\n",
    "**Como fazer:** Combine abordagens, por exemplo, um modelo estatístico para capturar a sazonalidade e uma rede neural para capturar padrões não lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testar diferentes modelos, usar validação cruzada e métricas como **MAE (Mean Absolute Error)** ou **RMSE (Root Mean Squared Error)** para avaliar o desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Exemplo de valores\n",
    "y_test = [10, 12, 14, 16, 18, 20]  \n",
    "y_pred = [11, 12, 13, 16, 19, 21]  \n",
    "\n",
    "# Cálculo do Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Cálculo do Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Exemplo de dados (substitua com seus próprios dados)\n",
    "X = np.random.rand(100, 2)  # Exemplo de features aleatórias\n",
    "y = np.random.rand(100)  # Exemplo de valores alvo aleatórios\n",
    "\n",
    "# 1. Definindo o modelo base\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 2. Definindo os parâmetros para o Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árvores na floresta\n",
    "    'max_depth': [None, 10, 20, 30]  # Profundidade máxima das árvores\n",
    "}\n",
    "\n",
    "# 3. Definindo o scorer para o MAE\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# 4. Configurando o Grid Search com K-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=mae_scorer, cv=kf)\n",
    "\n",
    "# 5. Executando o Grid Search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 6. Obtendo os melhores parâmetros e o melhor MAE\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(f\"Melhor MAE encontrado: {-grid_search.best_score_}\")\n",
    "\n",
    "# 7. Treinando o modelo com os melhores parâmetros e avaliando em um conjunto de teste separado\n",
    "# (Dividindo os dados em treino e teste novamente para a avaliação final)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinando o modelo com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões e avaliando o modelo final\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE) no conjunto de teste: {mae_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_leticia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
